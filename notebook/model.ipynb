{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaf8740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 20), (2000, 20), np.float64(0.2), np.float64(0.2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Cell 1: imports & data load (only if you don't have splits in memory) =====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load raw data (only if needed)\n",
    "df = pd.read_csv(\"../data/heart_disease.csv\")  # change path if needed\n",
    "y = df[\"Heart Disease Status\"].map({\"No\": 0, \"Yes\": 1}).astype(int)\n",
    "X = df.drop(columns=[\"Heart Disease Status\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e109201b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 35), (2000, 35))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Cell 2: load preprocessor & transform =====\n",
    "preprocessor = joblib.load(\"preprocessor.joblib\")\n",
    "\n",
    "X_train_pre = preprocessor.transform(X_train)\n",
    "X_test_pre  = preprocessor.transform(X_test)\n",
    "\n",
    "# Feature names (optional but nice for inspection)\n",
    "def get_feature_names(preprocessor, num_cols=None, cat_cols=None):\n",
    "    # Try to recover names from the fitted object\n",
    "    num_cols = getattr(preprocessor, \"transformers_\", [])[0][2] if num_cols is None else num_cols\n",
    "    cat_cols = getattr(preprocessor, \"transformers_\", [])[1][2] if cat_cols is None else cat_cols\n",
    "    # OneHot names\n",
    "    ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "    cat_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "    return list(num_cols) + cat_names\n",
    "\n",
    "try:\n",
    "    feature_names = get_feature_names(preprocessor)\n",
    "    X_train_df = pd.DataFrame(X_train_pre, columns=feature_names, index=X_train.index)\n",
    "    X_test_df  = pd.DataFrame(X_test_pre,  columns=feature_names, index=X_test.index)\n",
    "except Exception:\n",
    "    X_train_df = pd.DataFrame(X_train_pre, index=X_train.index)\n",
    "    X_test_df  = pd.DataFrame(X_test_pre,  index=X_test.index)\n",
    "\n",
    "X_train_df.shape, X_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ada78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3: evaluation helpers =====\n",
    "def evaluate_model(y_true, y_proba, threshold=0.5, label=\"model\"):\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    metrics = {\n",
    "        \"label\": label,\n",
    "        \"threshold\": threshold,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_proba),\n",
    "        \"avg_precision\": average_precision_score(y_true, y_proba)  # PR-AUC\n",
    "    }\n",
    "    print(f\"\\n=== {label} @ threshold={threshold:.2f} ===\")\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, zero_division=0))\n",
    "    print(\"Scores:\", {k: round(v, 4) for k, v in metrics.items() if k not in [\"label\"]})\n",
    "    return metrics\n",
    "\n",
    "def find_best_threshold(y_true, y_proba, target=\"f1\", min_precision=None):\n",
    "    \"\"\"Grid-search a threshold on PR curve. If min_precision is set, choose highest recall meeting it.\"\"\"\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    thresholds = np.append(thresholds, 1.0)  # align lengths\n",
    "\n",
    "    best_t, best_score = 0.5, -1\n",
    "    if min_precision is not None:\n",
    "        # choose the highest recall while meeting a minimum precision\n",
    "        mask = precisions >= min_precision\n",
    "        if mask.any():\n",
    "            idx = np.argmax(recalls[mask])  # highest recall among qualifying points\n",
    "            # Map back to full arrays\n",
    "            valid_idxs = np.where(mask)[0]\n",
    "            best_idx = valid_idxs[idx]\n",
    "            best_t = thresholds[best_idx]\n",
    "            best_score = recalls[best_idx]\n",
    "            return best_t, {\"criterion\": f\"recall with precision≥{min_precision}\", \"score\": best_score}\n",
    "    # otherwise maximize metric\n",
    "    for p, r, t in zip(precisions, recalls, thresholds):\n",
    "        f1 = 0 if (p + r) == 0 else 2*p*r/(p+r)\n",
    "        score = {\"f1\": f1, \"recall\": r, \"precision\": p}.get(target, f1)\n",
    "        if score > best_score:\n",
    "            best_score, best_t = score, t\n",
    "    return best_t, {\"criterion\": target, \"score\": best_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cdafead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogReg (balanced) @ threshold=0.50 ===\n",
      "Confusion matrix:\n",
      " [[815 785]\n",
      " [214 186]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.51      0.62      1600\n",
      "           1       0.19      0.47      0.27       400\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.49      0.49      0.45      2000\n",
      "weighted avg       0.67      0.50      0.55      2000\n",
      "\n",
      "Scores: {'threshold': 0.5, 'accuracy': 0.5005, 'precision': 0.1916, 'recall': 0.465, 'f1': 0.2713, 'roc_auc': 0.4862, 'avg_precision': 0.1935}\n",
      "\n",
      "=== LogReg tuned ({'criterion': 'recall with precision≥0.6', 'score': np.float64(0.0)}) @ threshold=1.00 ===\n",
      "Confusion matrix:\n",
      " [[1600    0]\n",
      " [ 400    0]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      1600\n",
      "           1       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.40      0.50      0.44      2000\n",
      "weighted avg       0.64      0.80      0.71      2000\n",
      "\n",
      "Scores: {'threshold': np.float64(1.0), 'accuracy': 0.8, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'roc_auc': 0.4862, 'avg_precision': 0.1935}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 4: Logistic Regression baseline =====\n",
    "lr = LogisticRegression(max_iter=2000, class_weight=\"balanced\", n_jobs=None, solver=\"lbfgs\")\n",
    "lr.fit(X_train_df, y_train)\n",
    "\n",
    "lr_proba = lr.predict_proba(X_test_df)[:, 1]\n",
    "\n",
    "# Default 0.5 threshold\n",
    "lr_metrics_default = evaluate_model(y_test, lr_proba, 0.5, label=\"LogReg (balanced)\")\n",
    "\n",
    "# Tune threshold for medical preference: prioritize recall but keep precision reasonable\n",
    "best_t, info = find_best_threshold(y_test, lr_proba, target=\"f1\", min_precision=0.6)\n",
    "lr_metrics_tuned = evaluate_model(y_test, lr_proba, best_t, label=f\"LogReg tuned ({info})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8efd358c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RandomForest @ threshold=0.50 ===\n",
      "Confusion matrix:\n",
      " [[1600    0]\n",
      " [ 400    0]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      1600\n",
      "           1       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.40      0.50      0.44      2000\n",
      "weighted avg       0.64      0.80      0.71      2000\n",
      "\n",
      "Scores: {'threshold': 0.5, 'accuracy': 0.8, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'roc_auc': 0.4963, 'avg_precision': 0.1969}\n",
      "\n",
      "=== RandomForest tuned ({'criterion': 'recall with precision≥0.6', 'score': np.float64(0.0)}) @ threshold=1.00 ===\n",
      "Confusion matrix:\n",
      " [[1600    0]\n",
      " [ 400    0]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      1600\n",
      "           1       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.40      0.50      0.44      2000\n",
      "weighted avg       0.64      0.80      0.71      2000\n",
      "\n",
      "Scores: {'threshold': np.float64(1.0), 'accuracy': 0.8, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'roc_auc': 0.4963, 'avg_precision': 0.1969}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BMI                           0.086626\n",
       "CRP Level                     0.085910\n",
       "Homocysteine Level            0.084742\n",
       "Sleep Hours                   0.083230\n",
       "Triglyceride Level            0.080715\n",
       "Cholesterol Level             0.079873\n",
       "Fasting Blood Sugar           0.076961\n",
       "Age                           0.075570\n",
       "Blood Pressure                0.073967\n",
       "Alcohol Consumption_Medium    0.011827\n",
       "Exercise Habits_High          0.011371\n",
       "Exercise Habits_Medium        0.011126\n",
       "Diabetes_Yes                  0.011078\n",
       "High Blood Pressure_Yes       0.010946\n",
       "Exercise Habits_Low           0.010902\n",
       "Sugar Consumption_Medium      0.010673\n",
       "Low HDL Cholesterol_No        0.010672\n",
       "Family Heart Disease_No       0.010657\n",
       "Sugar Consumption_Low         0.010643\n",
       "High Blood Pressure_No        0.010619\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== Cell 5: Random Forest =====\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_df, y_train)\n",
    "rf_proba = rf.predict_proba(X_test_df)[:, 1]\n",
    "\n",
    "rf_metrics_default = evaluate_model(y_test, rf_proba, 0.5, label=\"RandomForest\")\n",
    "\n",
    "best_t, info = find_best_threshold(y_test, rf_proba, target=\"f1\", min_precision=0.6)\n",
    "rf_metrics_tuned = evaluate_model(y_test, rf_proba, best_t, label=f\"RandomForest tuned ({info})\")\n",
    "\n",
    "# Optional: top features\n",
    "if 'columns' in dir(X_train_df):\n",
    "    importances = pd.Series(rf.feature_importances_, index=X_train_df.columns).sort_values(ascending=False)\n",
    "    display(importances.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6a7fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg CV ROC-AUC: mean=0.5118 ± 0.0225\n",
      "RandomForest CV ROC-AUC: mean=0.5086 ± 0.0121\n",
      "GradientBoosting CV ROC-AUC: mean=0.4981 ± 0.0218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.51795654, 0.47321289, 0.47167236, 0.52286133, 0.50495117])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Cell 7: Cross-validated ROC-AUC on training set =====\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def cv_auc(model, X, y, label):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    print(f\"{label} CV ROC-AUC: mean={scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "    return scores\n",
    "\n",
    "cv_auc(LogisticRegression(max_iter=2000, class_weight=\"balanced\"), X_train_df, y_train, \"LogReg\")\n",
    "cv_auc(RandomForestClassifier(n_estimators=400, class_weight=\"balanced_subsample\", random_state=42, n_jobs=-1),\n",
    "       X_train_df, y_train, \"RandomForest\")\n",
    "cv_auc(GradientBoostingClassifier(random_state=42), X_train_df, y_train, \"GradientBoosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4fd3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best params: {'n_estimators': 400, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'class_weight': 'balanced_subsample'}\n",
      "Best CV ROC-AUC: 0.51908056640625\n",
      "\n",
      "=== RF best (default thr) @ threshold=0.50 ===\n",
      "Confusion matrix:\n",
      " [[1575   25]\n",
      " [ 397    3]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88      1600\n",
      "           1       0.11      0.01      0.01       400\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.45      0.50      0.45      2000\n",
      "weighted avg       0.66      0.79      0.71      2000\n",
      "\n",
      "Scores: {'threshold': 0.5, 'accuracy': 0.789, 'precision': 0.1071, 'recall': 0.0075, 'f1': 0.014, 'roc_auc': 0.4913, 'avg_precision': 0.1914}\n",
      "\n",
      "=== RF best tuned ({'criterion': 'recall with precision≥0.6', 'score': np.float64(0.0)}) @ threshold=1.00 ===\n",
      "Confusion matrix:\n",
      " [[1600    0]\n",
      " [ 400    0]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      1600\n",
      "           1       0.00      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.40      0.50      0.44      2000\n",
      "weighted avg       0.64      0.80      0.71      2000\n",
      "\n",
      "Scores: {'threshold': np.float64(1.0), 'accuracy': 0.8, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'roc_auc': 0.4913, 'avg_precision': 0.1914}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': \"RF best tuned ({'criterion': 'recall with precision≥0.6', 'score': np.float64(0.0)})\",\n",
       " 'threshold': np.float64(1.0),\n",
       " 'accuracy': 0.8,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'f1': 0.0,\n",
       " 'roc_auc': 0.491346875,\n",
       " 'avg_precision': 0.19140591559688058}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Cell 8: RandomizedSearchCV for RandomForest =====\n",
    "param_dist = {\n",
    "    \"n_estimators\": [200, 300, 400, 600, 800],\n",
    "    \"max_depth\": [None, 6, 10, 14, 18],\n",
    "    \"min_samples_split\": [2, 4, 6, 8],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.5, 0.8],\n",
    "    \"class_weight\": [\"balanced\", \"balanced_subsample\"]\n",
    "}\n",
    "\n",
    "rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_rs = RandomizedSearchCV(\n",
    "    rf_base, param_distributions=param_dist, n_iter=40,\n",
    "    scoring=\"roc_auc\", n_jobs=-1, cv=5, random_state=42, verbose=1\n",
    ")\n",
    "rf_rs.fit(X_train_df, y_train)\n",
    "\n",
    "print(\"Best params:\", rf_rs.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", rf_rs.best_score_)\n",
    "\n",
    "rf_best = rf_rs.best_estimator_\n",
    "rf_best_proba = rf_best.predict_proba(X_test_df)[:, 1]\n",
    "evaluate_model(y_test, rf_best_proba, 0.5, label=\"RF best (default thr)\")\n",
    "best_t, info = find_best_threshold(y_test, rf_best_proba, target=\"f1\", min_precision=0.6)\n",
    "evaluate_model(y_test, rf_best_proba, best_t, label=f\"RF best tuned ({info})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c06557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
